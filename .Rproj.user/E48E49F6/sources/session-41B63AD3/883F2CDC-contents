filename <- "murders.csv"
filename <- "murders.csv"

path <- system.file("extdata", package = "dslabs")

path

fullpath <- file.path(path,filename)

fullpath

file.copy(fullpath, getwd())


file.exists(filename)


read_lines("murders.csv", n_max = 3)



dat <- read_csv(filename)

###YOu can see that is a tibble the object because we are using a reading function 

head(dat)
class(dat)

path <- system.file("extdata", package = "dslabs")


path

list.files(path)


filename <- "murders.csv"
filename2 <- "life-expectancy-and-fertility-two-countries-example.csv"
filename3 <- "fertility-two-countries-example.csv" 


dat=read.csv(file.path(path,filename))
dat2=read.csv(file.path(path,filename2))
dat3=read.csv(file.path(path,filename3))
class(dat)

url <- "https://raw.githubusercontent.com/rafalab/dslabs/master/inst/extdata/murders.csv"


dat=read.csv(url)

### If you want to just download a temporary file and after that erase the file you 
## can use the next code 

tmp_filename <- tempfile()
download.file(url, tmp_filename)
dat <- read_csv(tmp_filename)
file.remove(tmp_filename)



### Now we are going to wrangle 

getwd()

filename4 <- "times.csv"

my_path <- "C:/Users/omarc/projects/murders-me"
dat4=read.csv(file.path("C:/Users/omarc/projects/murders-me",filename4))
dat4

filename5 <- "times2.xlsx"

dat5=read_excel(file.path(my_path, filename5),sheet = "2016")
dat5


####This statement is no longer true as of R4.0; the base R 
###import functions previously imported character columns as factors, 
###but the functions no longer do this automatic conversion. If you want 
##to read in the character columns as factors, you can supply the argument 
##stringsAsFactors = T.

url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data" 


read_lines(url, n_max = 3)

#### This is the real usefulness of read_lines that allows you to check on the 
## file if you dont have any information about the file 



getwd()


download.file(url,"murders-copy")

filename6 <- "murders-copy"

### If you dont have a heather with the name of the columns you use on the 
## preinstalled col_names = FALSE


read_csv(file.path(getwd(), filename6), col_names = FALSE)



#### In order to make  it work in the readr package you use the header false argument
##

dat6=read.csv(file.path(getwd(),filename6), header = FALSE)


help("read_csv")
help("readr")

nrow(dat6)


length(names(dat6))


data("gapminder")


tidydata <- gapminder %>% filter( country %in% c("South Korea", "Germany"))%>%
  select(country,year,fertility)

head(tidydata)


tidydata %>% ggplot(aes(year, fertility, color = country))+
  geom_point()



path <- system.file("extdata", package = "dslabs") 




list.files(path)


filename <- file.path(path, "fertility-two-countries-example.csv" )

wide_data <- read_csv(filename)

head(wide_data, 10)

wide_data



#### Now we are going to tidy a little bit that wide data so we are going to 
## be able to analyse it 




wide_data %>% pivot_longer(c(`1960`:`2015`))




wide_data %>% select(country, '1960':'1965')



wide_data %>% pivot_longer(`1960`:`2015`)



new_tidy_data <- wide_data %>% pivot_longer(-country, names_to = "year", values_to = "fertility",
                                            names_transform = list(year = as.numeric))


new_tidy_data                                           


new_tidy_data_g <- new_tidy_data %>% ggplot(aes(year, fertility, color = country))+
  geom_point()


new_tidy_data_g




#### NOw we are going to try something a little bit more complicated 


path_2 <- system.file("extdata", package = "dslabs")

list.files(path_2)


filename2 <- file.path(path_2, "life-expectancy-and-fertility-two-countries-example.csv")


raw_dat <- read_csv(filename2)


raw_dat
### Interesting use of select 


select(raw_dat, 1:4)


dat <- raw_dat %>% pivot_longer(-country)


head(dat)



wrong_tidy_dat <- dat %>% separate(name, c("year", "name"), convert = TRUE)

wrong_tidy_dat


#### We see how the code is ignoring the expectancy because is following a under
## score we see that in this code we don't use the third argument of sep = 
## because that's the default separator 




tidy_dat <- dat %>% separate(name, c("year", "name"), sep = "_",
                             extra = "merge", convert = TRUE)


tidy_dat

### We can see how the different arguments play a roll in the code the first 
## argument is the column to separate the second the new column names the sep
## is the character used to separate the data and the extra argument 
### in this case is the one telling the code to ignore the second underscore 
## and to merge the data he convert is converting the years in to numbers 



tidy_dat <- tidy_dat %>% pivot_wider()


### We use the pivot_wider which objective is to assign a name to each column 
## at the end 


tidy_dat


#### Let's try another approximation to tidy that data 

dat <- raw_dat %>% pivot_longer(-country)

head(dat)

tidy_dat_2 <- dat %>% separate(name, c("year", "name_1", "name_2"), 
                               fill = "right",convert = TRUE)


tidy_dat_2


tidy_dat_2 <- tidy_dat_2 %>% unite(name, name_1, name_2 , sep = "_")%>%
  spread(name, value)%>%
  rename(fertility = fertility_NA)



tidy_dat_2

#### Tidydata assessment 



path <- getwd()

list.files(path)

filename <- file.path(path,"times.csv")

times <- read_csv(filename)


times


tidy_times <- times %>% pivot_longer(`2015`:`2017`, names_to = "year", 
                                values_to = "time")

tidy_times





tidy_times_wrong <- times %>% pivot_longer(age_group, names_to = "year", 
                                     values_to = "times")


tidy_times_wrong

path <- getwd()

list.files(path)

filename <- file.path(path,"dat_wide.csv")

dat_wide <- read_csv(filename)

dat_wide


tidy_dat <- dat_wide %>% pivot_longer(-state,-year,-population, 
                        names_to = "desease", values_to = "count" )


names(dat_wide)                                  
            

dat_tidy <- dat_wide %>%pivot_longer(HepatitisA:Rubella, 
                                     names_to = "disease", values_to = "count")
  

dat_tidy


head(dat_wide)

#####



head(tidy_times)


tidy_times %>% pivot_wider(names_from = year, values_from = time)


head(dat)

path <- getwd()
list.files(path)

filename <- file.path(path,"State.csv")


deseases <- read_csv(filename)


deseases 
 



tidy_deseases<- deseases %>% pivot_wider(names_from = var, values_from = people)
                              


tidy_deseases

help("read_delim")



path <- getwd()

list.files(path)

filename <- file.path(path, "race.csv")

raw_race <- read_csv(filename, col_types = "dcccc")

raw_race

tidy_race <- raw_race %>% pivot_longer(-age_group, names_to = "key",
              values_to = "value")%>%
              separate(col = key, into = (c("year", "variable_name")),
                       sep = "_")%>%
             pivot_wider(names_from = variable_name, values_from = value)



tidy_race

path <- getwd()

list.files(path)

filename <- file.path(path,"players2.csv") 

raw_players2 <- read_csv(filename, col_types = "cd")

raw_players2


tidy_players2 <- players2 %>% separate(col = key, into = (c("player", "variable_name"))
                     ,sep = "_", extra = "merge")%>%
                pivot_wider(names_from = variable_name, values_from = value)





data("co2")


head(co2)


str(co2)


co2_wide <- co2 %>% data.frame(matrix(co2, ncol = 12, byrow = TRUE))

### That's spreading the number of observations by row having in to account
## that the data set is having one co2 observation per month 


co2_wide


co2_wide <- data.frame(matrix(co2, ncol = 12, byrow = TRUE))%>%
                    setNames(1:12)%>%
                    mutate(year = as.character(1959:1997))



co2_wide


#### Now we are going to tidy the data by creating a month column with 
## the observations for each month 


tidy_co2 <- co2_wide %>% pivot_longer(-year, names_to = "month"
                                      , values_to = "co2")
                                      

tidy_co2


tidy_co2_plot <- tidy_co2 %>% ggplot(aes(as.numeric(month), co2, col = year))+
                              geom_line()


tidy_co2_plot


tidy_co2_summary <- tidy_co2 %>% group_by(year)%>% 
                    summarise(avg = mean(co2), sd = sd(co2))
                    


tidy_co2_summary

print(tidy_co2_summary, n = 39)

#### Now Lets try to tidy up the admissions test set to get some 
### interesting insides out of it 

library(dslabs)


data("admissions")

admissions
head(admissions)


tidy_admissions <- admissions %>% select(-applicants)%>% 
                   pivot_wider( names_from = gender,values_from = admitted)
                               


tidy_admissions


tidy_admissions_2 <- admissions %>% pivot_longer(cols = c(admitted, applicants)
                     , names_to = "key", values_to = "value")%>%
                    unite(col = column_1 , gender, key , sep = "_")%>%
                    pivot_wider(names_from = column_1, values_from = value)

tidy_admissions_2

#### Lets remember a little bit about left joins joining tables having 
## in to account that we have to have a column that has the same info 
## in each of the tables 


data()

data("polls_us_election_2016")
head(results_us_election_2016)
data("murders")
head(murders)

identical(polls_us_election_2016$state, murders$state)


tab <- left_join(polls_us_election_2016,murders, by = "state")


head(tab)

sum(is.na(tab$state))

tab_1 <- slice(murders, 1:6)%>% select(state,population)


tab_1


tab_2 <- slice(results_us_election_2016, c(1:3, 5, 7:8))%>%
         select(state, electoral_votes)

tab_2
names(results_us_election_2016)

#### If we want  table like tab 1 we can use the left join like this 

tab_1 %>% left_join(tab_2)


### If you would like a table like tab 2 

tab_1 %>% right_join(tab_2)

### notice thatthe na's now are comming from the tab 1 

### If we want to just see a table with information that is available in 
## both of the tables we can use inner_join and you can take that like 
## intersection 



inner_join(tab_1, tab_2)

### If you would like a union of the two tables and just filling any 
## missing info with na's you can just use 

full_join(tab_1, tab_2)


## The semi_join allow us to keep info of the first table based on the 
## information that you have available in the second one 

semi_join(tab_1,tab_2)

#### anti_join is going to do the opposite of semi join is going to 
## keep the info of the tab_1 based on info that we dont have in tab_2 

anti_join(tab_1,tab_2)


### Let's see how the bind fuctions work this functions just look to join 
## tables by columns but not by an specific argument only allowding it
## if they have the same row dimentions 

tab_3 <- tab[, 1:3]

head(tab_3)

tab_4 <- tab[, 4:6]

head(tab_4)


tab_5 <- tab[, 7:9]

head(tab_5)



new_tab <- bind_cols(tab_3,tab_4,tab_5)


head(new_tab)



## We can bind them by rows too if we use the bind rows function 




tab_6 <- tab[1:2,]
tab_7 <- tab[3:4,]


bind_rows(tab_6,tab_7)


### the same operators that we can use in vectors usually on base R 
## we can use the same just totables if we have loaded the dplyr package 
## or tidyverse the tables have to have the same columns for this to work 



operators_tab_1 <- tab[1:5,]

operators_tab_2 <- tab[3:7,]

intersect(operators_tab_1,operators_tab_2)

### that's going to show us just the rows that intersect in this case 
## thats going to be the rows 3 to 5 which are present in both of the 
## tables 


union(operators_tab_1,operators_tab_2)


# that's going to give us the 1 to 7 rows 


## we have a set difference function with is going to in the first element 
## but that are not in the second one 



setdiff(operators_tab_1,operators_tab_2)

### the function is not simetric if you change the order of the elements 
## you are going to have different results 

setdiff(operators_tab_2,operators_tab_1)



### Another useful function is going to be setequal 
### where besides the info of they being equal or not depending on the 
## order of the elements wich is already useful is going to tell you 
## where is that they are not equal 


setequal(operators_tab_1,operators_tab_2)


help(dim)

### dim is just gong to give to the dimentions of a table 


### Assesment tidy data 


path<- getwd()
list.files(path)

filename <- file.path(path,"tab1.txt")
tab_1_assesment <- read_csv(filename, col_names = FALSE)


tab_1_assesment

filename_2 <- file.path(path,"tab2.txt")

tab_2_assesment <- read.csv(filename_2, col.names = FALSE)




tab_1_assesment

tab_2_assesment

dim(tab_1_assesment)




new_order_1 <- murders %>% select(state,population)%>%
             filter(state %in% c("Alabama", "Alaska","Arizona","Delaware"
              ,"District of Columbia"))
 


new_order_1




new_order_2 <- results_us_election_2016 %>% select(state,electoral_votes)%>%
               filter(state!= "Arkansas")%>%group_by(state)%>% arrange(state)
               


new_order_

new_order_2 <- new_order_2[1:6,]

new_order_2


dim(new_order_1)



dim(new_order_2)


### Left join only hat in to account the states that were in both 
### of the tables 

dat <- left_join(new_order_1, new_order_2)


dim(dat)

dat


### Lets try the other joins 



right <- right_join(new_order_1,new_order_2, by = "state")


dim(right)


inner <- inner_join(new_order_1, new_order_2, by = "state")

inner

dim(inner)


semi <- semi_join(new_order_1,new_order_2, by = "state")


dim(semi)



df1 <- data.frame(x = c("a","b"), y= c("a","a"))

df1

df2 <- data.frame(x = c("a","a"), y = c("a","b"))


df2

union(df1,df2)

intersect(df1,df2)


setdiff(df1,df2)


### Let's work on the Lahman data set 


install.packages("Lahman")


library(Lahman)

head(Batting)


       
       
top <- Batting %>% 
       filter(yearID == 2016) %>%
       arrange(desc(HR)) %>%    
       slice(1:10)                                               



head(top)

top %>% as_tibble()

head(People)


People %>% as_tibble()



top_names <- top %>% left_join(People)%>%
             select(playerID, nameFirst, nameLast, HR)


top_names

head(top_names)




top_names_right <- top %>% right_join(People)%>%
                   select(playerID, nameFirst, nameLast, HR)


head(top_names_right)


top_names_full <- top %>% full_join(People)%>%
                  select(playerID, nameFirst, nameLast, HR)



head(top_names_full)


head(Salaries)



top_salaries <- Salaries %>% filter(yearID == 2016) %>%
                right_join(top_names)%>% 
                select(nameFirst, nameLast, teamID, HR, salary)



head(top_salaries)



data("AwardsPlayers")

AwardsPlayers

head(AwardsPlayers)


top_players <- top %>% select(playerID, yearID, teamID, HR) 
### Reember that top was already filtered by year 2016              


Awards_players_2016 <- AwardsPlayers %>% filter(yearID == 2016)

#### Like this we are only going to keep the the players in top players 
## that are going to be in the awards players with the semi join function
###that we already filtered 
## so is only going to include the awards from 2016

top_awards <- semi_join(top_players,Awards_players_2016,by = "playerID")
            
              
top_10_HR <- top_players[1:10,]            
top_10_HR
 
### In this case we are only going to get the top 10 by HR that we just 
## organized 
#### And we are going to use the anti join to see only the players that 
## are not in the top 10 HR that we just created
             
new_top_awards <- anti_join(Awards_players_2016,top_10_HR, by = "playerID")
 

###          
new_top_awards_unique <- new_top_awards %>% distinct(playerID, .keep_all = TRUE)


head(new_top_awards_unique)

     
nrow(new_top_awards_unique)


new_top_awards



head(new_top_awards)

nrow(new_top_awards)

head(top_awards)              
              
nrow(top_awards)             





top_awards





















