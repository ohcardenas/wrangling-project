### text mining



library(tidyverse)
library(lubridate)
library(ggplot2)
library(tidyr)
library(scales)


## We can extract data directly from twitter with rtweet too 

### in this case we can use data readily available to us in the next link 

library(Lahman)
library(tidyverse)
library(dslabs)
ds_theme_set()


Teams %>% head


### sccatter plots are the visualization tool for exelence making linear regressions

### Lets create a correlation scatter plot between two new variables that 
## we will create in the dataset 


Teams %>% filter( yearID %in% 1961:2001)%>%
          mutate(HR_per_game = HR / G , R_per_game = R / G ) %>%
          ggplot(aes(HR_per_game, R_per_game))+
          geom_point(alpha = 0.5)


### lets do the same analysis to SB stolen basis per game and runs per game 


Teams %>% filter( yearID %in% 1961:2001)%>%
          mutate( SB_per_game = SB / G , R_per_game = R / G)%>%
          ggplot(aes(SB_per_game, R_per_game))+
          geom_point( alpha = 0.5)

## The correlation of stolen bases and the runs per game is not as strong as with 
## home runs 


## Now lets look at the correlation between  BB base on balls and the runs in a 
## game 

Teams %>% filter( yearID %in% 1961:2001)%>%
          mutate( BB_per_game = BB / G , R_per_game = R / G)%>%
          ggplot(aes(BB_per_game, R_per_game))+
          geom_point( alpha = 0.5)


### Here we see a stronger correlation that with the SB stolen bases but this can
## be do to confounding a concept that we are going to review in debt 



## Lets see what's the correlation of AB at bat per game and runs per game 
## we are going to do the same process as with the other variables 


Teams %>% filter( yearID %in% 1961:2001)%>%
          mutate(AB_per_game = AB / G , R_per_game = R / G)%>%
          ggplot(aes(AB_per_game, R_per_game))+
          geom_point( alpha = 0.5)



## Now we are going to plot the wint rate vs the filding errors per game 




Teams %>% filter( yearID %in% 1961:2001)%>%
          mutate(Wins_per_game = W / G, E_per_game = E / G)%>%
          ggplot(aes(E_per_game, Wins_per_game))+
          geom_point( alpha = 0.5)



### Lets make a correlation between triples X3B and doubles  X2B per game to see how 
## the two case of successes correlate 



Teams %>%  filter( yearID %in% 1961:2001)%>%
           mutate(two_B_per_game = X2B / G , three_B_per_game = X3B / G )%>%
           ggplot(aes(two_B_per_game,three_B_per_game))+
           geom_point( alpha = 0.5)
           




library(Lahman)

data("Teams")


Teams %>% head()

r_1 <- Teams %>% filter( yearID %in% 1961:2001)%>%
          mutate( Wins_per_game = W / G, E_per_game = E / G ) %>%
          summarise( r = cor(Wins_per_game, E_per_game)) %>%
          pull(r)


signif(r_1,3)

r_2 <- Teams %>% filter( yearID %in% 1961:2001)%>%
                mutate( X2B_per_game = X2B / G , X3B_per_game = X3B / G) %>%
                summarise( r = cor(X2B_per_game, X3B_per_game))%>%
                pull(r)


signif(r_2, 3)


### Let's understand correlation between averages and standart deviations 

library(tidyverse)
install.packages("HistData")

library(HistData)
data("GaltonFamilies")

## remember thats how the set seed used to work 

set.seed(1983, sample.kind = "Rounding")

GaltonFamilies %>% head



### In this code by grouping by family and and 


galton_heights <- GaltonFamilies %>%
                  filter(gender == "male")%>%
                  group_by(family)%>%
                  sample_n(1)%>%
                  ungroup() %>%
                  select( father, childHeight)%>%
                  rename(son = childHeight)
                  

galton_heights %>% summarise( mean(father), sd(father), mean(son), sd(son))



galton_heights %>% ggplot(aes(father, son))+
                   geom_point(alpha = 0.5)


##We cannot see a clear relationship between the two variables even if they 
##do have a correalationship 

### lets compute a correlation of two variables using R 



galton_heights_2 <- GaltonFamilies %>%
                    filter( childNum == 1 & gender == "male")%>%
                    select( father, childHeight)%>%
                    rename( son = childHeight)



nrow(galton_heights_2)


galton_heights_2 %>% summarise(cor(father,son))


set.seed(0)


my_sample <-  slice_sample(galton_heights_2, n = 25, replace = TRUE)


R <- my_sample %>% summarize(r = cor(father, son))



R


B <- 10000
N <- 25 

R <- replicate(B, {
  
  
  sample <- slice_sample(galton_heights_2, n = N, replace = TRUE)%>%
  summarise(r = cor(father, son))%>% .$r
  

})



print(R)


data.frame(R) %>% ggplot(aes(R))+ geom_histogram(binwidth = 0.05, color= "firebrick")



mean(R)


### As we can see because of the small size of the population we can see that 
## sd or our random varible is big 

sd(R)



## we know that because roh is a random variblable the central limit thorem 
## aplies here too some for a random varible with a big large amount of abservations
## the variable behaves normally 


             
data.frame(R) %>%
              ggplot(aes(sample = R)) +
              stat_qq() +
              geom_abline(intercept = mean(R), slope = sqrt((1-mean(R)^2)/(N-2))
                          ,color = "blue")


## We can see that the behavior of the curve is not normal 


library(Lahman)


data("Teams")


head(Teams)


cor_1 <-Teams %>% filter( yearID %in% 1961:2001)%>%
          mutate(R_per_game = R / G , AB_per_game = AB / G) %>%
          summarise(r = cor(R_per_game, AB_per_game))%>% .$r



signif(cor_1, 3)


### To construct a conditional mean the estimated mean of a son height based on 
## fathers height

## let's say we know that the fater is 72 inches 



galton_heights_2 <- GaltonFamilies %>%
  filter( childNum == 1 & gender == "male")%>%
  select( father, childHeight)%>%
  rename( son = childHeight)


## ltes see how many entries we have for fathers that are 72 inches 


sum(galton_heights_2$father == 72)

### if we change that for 72.5 is even less data 


sum(galton_heights_2$father == 72.5)



## let's round that 72 inches so we have more data 

conditional_avg <- galton_heights_2 %>%
                   filter(round(father) == 72)%>%
                   summarise(avg = mean(son))%>%
                   pull(avg)

conditional_avg

### this would be our conditional average notice that is much higher than the 
##69 inches average 


### noe we havve many more entries 2012




### Lets statify that fathers height having in to account the values available in
## inches and make a graph to see the influesnze of the father height on the sons
## height 



galton_heights_2 %>% mutate(father_strata = factor(round(father)))%>%
                  ggplot(aes(father_strata, son)) +
                  geom_boxplot()+
                  geom_point()



## center of each plot
### Another way of stratifying you values with the group by funtion and 
### computing the contidional avergae after with summarize 



galton_heights_2 %>% mutate(father = round(father))%>%
                     group_by(father)%>%
                     summarise(son_conditional_avg = mean(son))%>%
                     ggplot(aes(father, son_conditional_avg)) + 
                     geom_point()
                     




### Lets add a reggression line to the standarised data 



r <- galton_heights_2 %>% summarise(r = cor(father, son)) %>% pull(r)

## with the scale command we are just going to normalize the data 


help("scale")

galton_heights_2 %>% mutate(father = scale(father), son = scale(son)) %>%
                     mutate(father = round(father))%>%
                     group_by(father)%>%
                     summarise(son = mean(son))%>%
                     ggplot(aes(father, son))+
                     geom_point()+
                     geom_abline(intercept = 0, slope = r)




#### Add reggression line to the original data

mu_x <- mean(galton_heights_2$father)
mu_y <- mean(galton_heights_2$son)


s_x <- sd(galton_heights_2$father)
s_y <- sd(galton_heights_2$son)

r <- cor(galton_heights_2$father, galton_heights_2$son)


m <- r * mu_y/mu_x

b <- mu_y - m *mu_x


## this is going to be the linear regression 

galton_heights_2 %>% ggplot(aes(father, son))+
                     geom_point(alpha = 0.5) +
                     geom_abline(intercept = b , slope = m)
    

### lets plot in standarized units and see that the intercet is 0 

galton_heights_2 %>% ggplot(aes(scale(father), scale(son))) +
                     geom_point(alpha = 0.5) + 
                     geom_abline(intercept = 0 , slope = r)





galton_heights_2 %>% mutate(z_father = round((father - mean(father))/ sd(father))) %>%
                     filter(z_father %in% -2:2)%>%
                     ggplot() +
                     stat_qq(aes(sample = son))+
                     facet_wrap(~z_father)



### Assesent question 6



0.5*3/2




library(HistData)

data("GaltonFamilies")


GaltonFamilies %>% head

set.seed(1989, sample.kind = "Rounding")

female_heights <- GaltonFamilies %>%
                  filter( gender == "female")%>%
                  group_by(family)%>%  
                  sample_n(1)%>%
                  ungroup()%>%
                  select(mother, childHeight)%>%
                  rename(daughter = childHeight)


female_heights
#### seems that we ust take a random sample of one the the families because
### we want to take just one of the daughters per family and to do it randomly 



m_x <- mean(female_heights$mother)

m_x

s_x <- sd(female_heights$mother)

s_x

m_y <- mean(female_heights$daughter)

s_y <- sd(female_heights$daughter)


r <- cor(female_heights$mother, female_heights$daughter)

r

### significatice numners of the correlation


signif(0.3245199, 4)


m <- r * s_y/s_x

signif(m, 4)



b <- m_y - (m*m_x)


signif(b, 4)


### What percentage in the variability of the daughters hight is explained by the 
## mothers hight

r^2*100


### Formula of the expected value of an x knowing that the biariate distribution 
## aplies for all of the groups included on the bivariate distribution 


60*m + b


### Lets start using a simpler formula for calculating the 
## intercept point and the slope of our linear regressions 


lm(son ~ father, data = galton_heights_2)




## We want the intercept of our model to be interretable so we run the same 
## model so we run the same model as before but now we substract the mean 


galton_heights_c <- galton_heights_2 %>%
                    mutate(father_centered = father- mean(father))


lm(son ~ father_centered, data = galton_heights_c)



#### lets come back to using lm to get the least square estimates 


set.seed(1983, sample.kind = "Rounding")


galton_heights_2 <- GaltonFamilies %>%
                    filter( gender == "male")%>%
                    group_by(family)%>%
                    sample_n(1)%>%
                    ungroup()%>%
                    select( father, childHeight)%>%
                    rename(son = childHeight)





### How do you built your RSS function

rss <- function (beta0, beta1){
   resid <- galton_heights_2$son - (beta0+beta1*galton_heights_2$father)
    return(sum(resid^2))
  
  }

### so we are just applying the residual sum of squares to each of the
## elements on the object galton_heights_2 the function being 
### sumatoria de Y - (B0+B1*x1) squared 



### So this would be a 3 dimentional plot with beta0 = x and beta1 = y 
## and RSS on the z axis 
### we'll keep beta0 constant to keep it simple 




beta1 = seq(0, 1, len=nrow(galton_heights_2))



library(HistData)
data("GaltonFamilies")
set.seed(1983)
galton_heights_2 <- GaltonFamilies %>%
  filter(gender == "male") %>%
  group_by(family) %>%
  sample_n(1) %>%
  ungroup() %>%
  select(father, childHeight) %>%
  rename(son = childHeight)



rss <- function(beta0, beta1){
  resid <- galton_heights_2$son - (beta0+beta1*galton_heights_2$father)
  return(sum(resid^2))
}


### the lenght argument is wtritten down a little bit weird

# plot RSS as a function of beta1 when beta0=25
beta1 = seq(0, 1, len=nrow(galton_heights_2))
results <- data.frame(beta1 = beta1,
                      rss = sapply(beta1, rss, beta0 = 25))



results %>% ggplot(aes(beta1, rss)) + geom_line() +
            geom_line(aes(beta1, rss), color = "firebrick")
  


results
## On this plot we can see a clear minimum for beta 1 at about 0.65
### Bu we dont know if thats the minimum for beta 0 we just know 
### that this is the minimum for beta1 when beta0 is fixed at 25 


## Is better to use calculus to we will use partial derivatives and well 
## set them at 0 and solve beta1 and beta0 

## of couse if we have many parameters this equations can get rather complx 
## and thats why we will use R to use functions to perform thi equations 
## for us 



fit <-lm( son ~ father, data = galton_heights_2)

fit

summary(fit)


## knowing that our Bs are random variables lets 
## try some montecarlo simulations


N <- 50 
B <- 10000

lse <- replicate(B, {
  
  sample_n(galton_heights_2, N, replace = TRUE)%>%
    lm(son ~ father, data = .)%>%
    .$coef

})
### we are going to take samples random samples of N size of our galton_heights_2


lse <- data.frame(beta_0 = lse[1,], beta_1 = lse[2,])
lse

library(gridExtra)

p1 <- lse %>% ggplot(aes(beta_0))+ geom_histogram( binwidth = 5
                                       , color = "firebrick")


p1                     
                     
p2 <- lse %>% ggplot(aes(beta_1))+ geom_histogram(binwidth = 0.1
                                                  ,color = "firebrick")

p2


grid.arrange(p1, p2, ncol = 2)




### summary statistics 


sample(galton_heights_2, N, replace = TRUE)%>%
       lm(son ~ father, data = .)%>%
        summary%>%
        .$coef



lse %>% summarise(se_0 = sd(beta_0), se_1 = sd(beta_1))


####  Its useful to know that the LSE can be strongly correlated 

lse %>% summarise(cor(beta_0, beta_1))



### however the correlation depends on how the predictors are defined or 
## transformed Here we standarize the father heights which changes xi to 
## xi- x --- x being the mean or aswe say x bar

N <-50 
B <- 10000

## standarized LSE 

lse_s <- replicate(B, {
   
    sample_n(galton_heights_2, N, replace = TRUE) %>%
    mutate(father = father - mean(father)) %>%
    lm(son ~ father , data = .) %>% .$coef

})

cor(lse[1,], lse[2,])



### A fast way of seeing graphically this the regession line between two 
## variables and their respective confidence intervals is to use the ggplot
## package 


galton_heights_2 %>% ggplot(aes(father, son)) +
                     geom_point()+
                     geom_smooth(method = "lm")


## notice that in this case you have to put the conditional variable first
## and after that you put the value to predict against what you do when 
## you use the lm function 


fit <- galton_heights_2 %>% lm(son ~ father , data = .)


Y_hat <- predict(fit , se.fit = TRUE)

names(Y_hat)

Y_hat


galton_heights_2 %>% mutate( Y_hat = predict(lm(son ~ father, data = .))) %>%
                     ggplot(aes(son, Y_hat)) +
                     geom_line()




